ingress-nginx:
  controller:
    # Fixes issue with injecting CA bundle in ValidatingWebhookConfiguration
    admissionWebhooks:
      certManager:
        enabled: true

    service:
      externalIPs:
      - 164.41.98.13
      nodePorts:
        http: "32766"
        https: "32767"

    metrics:
      enabled: true
      serviceMonitor:
        additionalLabels:
          release: kube-prometheus-stack
        enabled: true

    # fixes conflict with RKE2 ingress-nginx
    electionID: ingress-controller-leader
    ingressClassResource:
      name: external-nginx
      enabled: true
      default: false
      controllerValue: "k8s.io/external-ingress-nginx"

    keda:
      enabled: true
      minReplicas: 2
      maxReplicas: 3
      pollingInterval: 30
      cooldownPeriod: 300
      triggers:
      # TODO: Re-evaluate the following triggers after load testing
      # Scale if there are more than 500 connections waiting
      - type: prometheus
        metadata:
          serverAddress: http://kube-prometheus-stack-prometheus.monitoring.svc.cluster.local:9090
          metricName: nginx_connections_waiting_keda
          query: |
            sum(nginx_ingress_controller_nginx_process_connections{state="waiting"})
          threshold: "500"
      # - type: prometheus 
      #   metadata: 
      #     serverAddress: http://kube-prometheus-stack-prometheus.monitoring.svc.cluster.local:9090
      #     metricName: nginx_connections_active_keda 
      #     query: | 
      #       sum(avg_over_time(nginx_ingress_controller_nginx_process_connections{state="active"}[1m]))
      #     threshold: "100" 
      # Just for testing purposes
      # - type: prometheus
      #   metadata:
      #     serverAddress: http://kube-prometheus-stack-prometheus.monitoring.svc.cluster.local:9090
      #     metricName: nginx_ingress_controller_requests
      #     threshold: '5'
      #     query: sum(rate(nginx_ingress_controller_nginx_process_requests_total[2m]))


    # Define requests resources to avoid probe issues due to CPU utilization in busy nodes
    # ref: https://github.com/kubernetes/ingress-nginx/issues/4735#issuecomment-551204903
    # Ideally, there should be no limits.
    # https://engineering.indeedblog.com/blog/2019/12/cpu-throttling-regression-fix/
    resources:
      # limits:
      #   cpu: 384m
      #   memory: 384Mi
      requests:
        cpu: 384m
        memory: 384Mi

    # Pod anti affinity between ingress-nginx controller pods
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 100
          podAffinityTerm:
            labelSelector:
              matchExpressions:
              - key: app.kubernetes.io/name
                operator: In
                values:
                - ingress-nginx
              - key: app.kubernetes.io/instance
                operator: In
                values:
                - ingress-nginx
              - key: app.kubernetes.io/component
                operator: In
                values:
                - controller
            topologyKey: kubernetes.io/hostname

    #networkPolicy:
    #  enabled: true

    # TODO: Enable this when Grafana Tempo is installed
    # opentelemetry:
    #   enabled: true
